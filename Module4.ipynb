{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow version: 1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensor Flow version: {}\".format(tf.__version__))\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/NNDL/lib/python3.6/site-packages/ipykernel_launcher.py:71: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 38 samples\n",
      "Epoch 1/1000\n",
      "0s - loss: 0.8572 - val_loss: 0.8334\n",
      "Epoch 2/1000\n",
      "0s - loss: 0.8357 - val_loss: 0.8067\n",
      "Epoch 3/1000\n",
      "0s - loss: 0.8102 - val_loss: 0.7805\n",
      "Epoch 4/1000\n",
      "0s - loss: 0.7794 - val_loss: 0.7591\n",
      "Epoch 5/1000\n",
      "0s - loss: 0.7588 - val_loss: 0.7421\n",
      "Epoch 6/1000\n",
      "0s - loss: 0.7421 - val_loss: 0.7276\n",
      "Epoch 7/1000\n",
      "0s - loss: 0.7274 - val_loss: 0.7131\n",
      "Epoch 8/1000\n",
      "0s - loss: 0.7140 - val_loss: 0.7002\n",
      "Epoch 9/1000\n",
      "0s - loss: 0.7002 - val_loss: 0.6886\n",
      "Epoch 10/1000\n",
      "0s - loss: 0.6881 - val_loss: 0.6796\n",
      "Epoch 11/1000\n",
      "0s - loss: 0.6781 - val_loss: 0.6703\n",
      "Epoch 12/1000\n",
      "0s - loss: 0.6682 - val_loss: 0.6603\n",
      "Epoch 13/1000\n",
      "0s - loss: 0.6588 - val_loss: 0.6495\n",
      "Epoch 14/1000\n",
      "0s - loss: 0.6492 - val_loss: 0.6380\n",
      "Epoch 15/1000\n",
      "0s - loss: 0.6411 - val_loss: 0.6266\n",
      "Epoch 16/1000\n",
      "0s - loss: 0.6311 - val_loss: 0.6165\n",
      "Epoch 17/1000\n",
      "0s - loss: 0.6227 - val_loss: 0.6066\n",
      "Epoch 18/1000\n",
      "0s - loss: 0.6139 - val_loss: 0.5973\n",
      "Epoch 19/1000\n",
      "0s - loss: 0.6062 - val_loss: 0.5893\n",
      "Epoch 20/1000\n",
      "0s - loss: 0.5977 - val_loss: 0.5801\n",
      "Epoch 21/1000\n",
      "0s - loss: 0.5902 - val_loss: 0.5710\n",
      "Epoch 22/1000\n",
      "0s - loss: 0.5814 - val_loss: 0.5629\n",
      "Epoch 23/1000\n",
      "0s - loss: 0.5744 - val_loss: 0.5538\n",
      "Epoch 24/1000\n",
      "0s - loss: 0.5662 - val_loss: 0.5453\n",
      "Epoch 25/1000\n",
      "0s - loss: 0.5583 - val_loss: 0.5372\n",
      "Epoch 26/1000\n",
      "0s - loss: 0.5523 - val_loss: 0.5297\n",
      "Epoch 27/1000\n",
      "0s - loss: 0.5453 - val_loss: 0.5220\n",
      "Epoch 28/1000\n",
      "0s - loss: 0.5380 - val_loss: 0.5150\n",
      "Epoch 29/1000\n",
      "0s - loss: 0.5314 - val_loss: 0.5077\n",
      "Epoch 30/1000\n",
      "0s - loss: 0.5245 - val_loss: 0.5005\n",
      "Epoch 31/1000\n",
      "0s - loss: 0.5182 - val_loss: 0.4935\n",
      "Epoch 32/1000\n",
      "0s - loss: 0.5112 - val_loss: 0.4866\n",
      "Epoch 33/1000\n",
      "0s - loss: 0.5052 - val_loss: 0.4798\n",
      "Epoch 34/1000\n",
      "0s - loss: 0.4988 - val_loss: 0.4730\n",
      "Epoch 35/1000\n",
      "0s - loss: 0.4929 - val_loss: 0.4664\n",
      "Epoch 36/1000\n",
      "0s - loss: 0.4870 - val_loss: 0.4601\n",
      "Epoch 37/1000\n",
      "0s - loss: 0.4814 - val_loss: 0.4539\n",
      "Epoch 38/1000\n",
      "0s - loss: 0.4754 - val_loss: 0.4478\n",
      "Epoch 39/1000\n",
      "0s - loss: 0.4699 - val_loss: 0.4418\n",
      "Epoch 40/1000\n",
      "0s - loss: 0.4653 - val_loss: 0.4362\n",
      "Epoch 41/1000\n",
      "0s - loss: 0.4603 - val_loss: 0.4303\n",
      "Epoch 42/1000\n",
      "0s - loss: 0.4549 - val_loss: 0.4249\n",
      "Epoch 43/1000\n",
      "0s - loss: 0.4496 - val_loss: 0.4197\n",
      "Epoch 44/1000\n",
      "0s - loss: 0.4450 - val_loss: 0.4147\n",
      "Epoch 45/1000\n",
      "0s - loss: 0.4400 - val_loss: 0.4097\n",
      "Epoch 46/1000\n",
      "0s - loss: 0.4353 - val_loss: 0.4047\n",
      "Epoch 47/1000\n",
      "0s - loss: 0.4310 - val_loss: 0.3999\n",
      "Epoch 48/1000\n",
      "0s - loss: 0.4262 - val_loss: 0.3955\n",
      "Epoch 49/1000\n",
      "0s - loss: 0.4223 - val_loss: 0.3910\n",
      "Epoch 50/1000\n",
      "0s - loss: 0.4183 - val_loss: 0.3867\n",
      "Epoch 51/1000\n",
      "0s - loss: 0.4142 - val_loss: 0.3822\n",
      "Epoch 52/1000\n",
      "0s - loss: 0.4097 - val_loss: 0.3778\n",
      "Epoch 53/1000\n",
      "0s - loss: 0.4055 - val_loss: 0.3737\n",
      "Epoch 54/1000\n",
      "0s - loss: 0.4025 - val_loss: 0.3701\n",
      "Epoch 55/1000\n",
      "0s - loss: 0.3989 - val_loss: 0.3664\n",
      "Epoch 56/1000\n",
      "0s - loss: 0.3941 - val_loss: 0.3626\n",
      "Epoch 57/1000\n",
      "0s - loss: 0.3909 - val_loss: 0.3593\n",
      "Epoch 58/1000\n",
      "0s - loss: 0.3875 - val_loss: 0.3556\n",
      "Epoch 59/1000\n",
      "0s - loss: 0.3833 - val_loss: 0.3523\n",
      "Epoch 60/1000\n",
      "0s - loss: 0.3799 - val_loss: 0.3491\n",
      "Epoch 61/1000\n",
      "0s - loss: 0.3764 - val_loss: 0.3459\n",
      "Epoch 62/1000\n",
      "0s - loss: 0.3734 - val_loss: 0.3433\n",
      "Epoch 63/1000\n",
      "0s - loss: 0.3703 - val_loss: 0.3405\n",
      "Epoch 64/1000\n",
      "0s - loss: 0.3666 - val_loss: 0.3369\n",
      "Epoch 65/1000\n",
      "0s - loss: 0.3631 - val_loss: 0.3338\n",
      "Epoch 66/1000\n",
      "0s - loss: 0.3603 - val_loss: 0.3307\n",
      "Epoch 67/1000\n",
      "0s - loss: 0.3570 - val_loss: 0.3278\n",
      "Epoch 68/1000\n",
      "0s - loss: 0.3545 - val_loss: 0.3250\n",
      "Epoch 69/1000\n",
      "0s - loss: 0.3515 - val_loss: 0.3219\n",
      "Epoch 70/1000\n",
      "0s - loss: 0.3480 - val_loss: 0.3192\n",
      "Epoch 71/1000\n",
      "0s - loss: 0.3450 - val_loss: 0.3167\n",
      "Epoch 72/1000\n",
      "0s - loss: 0.3430 - val_loss: 0.3144\n",
      "Epoch 73/1000\n",
      "0s - loss: 0.3389 - val_loss: 0.3112\n",
      "Epoch 74/1000\n",
      "0s - loss: 0.3369 - val_loss: 0.3086\n",
      "Epoch 75/1000\n",
      "0s - loss: 0.3346 - val_loss: 0.3062\n",
      "Epoch 76/1000\n",
      "0s - loss: 0.3314 - val_loss: 0.3034\n",
      "Epoch 77/1000\n",
      "0s - loss: 0.3295 - val_loss: 0.3013\n",
      "Epoch 78/1000\n",
      "0s - loss: 0.3255 - val_loss: 0.2990\n",
      "Epoch 79/1000\n",
      "0s - loss: 0.3233 - val_loss: 0.2962\n",
      "Epoch 80/1000\n",
      "0s - loss: 0.3203 - val_loss: 0.2941\n",
      "Epoch 81/1000\n",
      "0s - loss: 0.3177 - val_loss: 0.2920\n",
      "Epoch 82/1000\n",
      "0s - loss: 0.3148 - val_loss: 0.2894\n",
      "Epoch 83/1000\n",
      "0s - loss: 0.3125 - val_loss: 0.2869\n",
      "Epoch 84/1000\n",
      "0s - loss: 0.3114 - val_loss: 0.2847\n",
      "Epoch 85/1000\n",
      "0s - loss: 0.3080 - val_loss: 0.2827\n",
      "Epoch 86/1000\n",
      "0s - loss: 0.3048 - val_loss: 0.2807\n",
      "Epoch 87/1000\n",
      "0s - loss: 0.3025 - val_loss: 0.2790\n",
      "Epoch 88/1000\n",
      "0s - loss: 0.3005 - val_loss: 0.2768\n",
      "Epoch 89/1000\n",
      "0s - loss: 0.2974 - val_loss: 0.2754\n",
      "Epoch 90/1000\n",
      "0s - loss: 0.2956 - val_loss: 0.2736\n",
      "Epoch 91/1000\n",
      "0s - loss: 0.2932 - val_loss: 0.2707\n",
      "Epoch 92/1000\n",
      "0s - loss: 0.2907 - val_loss: 0.2682\n",
      "Epoch 93/1000\n",
      "0s - loss: 0.2881 - val_loss: 0.2661\n",
      "Epoch 94/1000\n",
      "0s - loss: 0.2858 - val_loss: 0.2642\n",
      "Epoch 95/1000\n",
      "0s - loss: 0.2838 - val_loss: 0.2619\n",
      "Epoch 96/1000\n",
      "0s - loss: 0.2817 - val_loss: 0.2598\n",
      "Epoch 97/1000\n",
      "0s - loss: 0.2797 - val_loss: 0.2580\n",
      "Epoch 98/1000\n",
      "0s - loss: 0.2767 - val_loss: 0.2559\n",
      "Epoch 99/1000\n",
      "0s - loss: 0.2754 - val_loss: 0.2539\n",
      "Epoch 100/1000\n",
      "0s - loss: 0.2729 - val_loss: 0.2525\n",
      "Epoch 101/1000\n",
      "0s - loss: 0.2703 - val_loss: 0.2509\n",
      "Epoch 102/1000\n",
      "0s - loss: 0.2682 - val_loss: 0.2491\n",
      "Epoch 103/1000\n",
      "0s - loss: 0.2665 - val_loss: 0.2468\n",
      "Epoch 104/1000\n",
      "0s - loss: 0.2641 - val_loss: 0.2450\n",
      "Epoch 105/1000\n",
      "0s - loss: 0.2619 - val_loss: 0.2431\n",
      "Epoch 106/1000\n",
      "0s - loss: 0.2601 - val_loss: 0.2412\n",
      "Epoch 107/1000\n",
      "0s - loss: 0.2580 - val_loss: 0.2396\n",
      "Epoch 108/1000\n",
      "0s - loss: 0.2559 - val_loss: 0.2380\n",
      "Epoch 109/1000\n",
      "0s - loss: 0.2537 - val_loss: 0.2366\n",
      "Epoch 110/1000\n",
      "0s - loss: 0.2521 - val_loss: 0.2352\n",
      "Epoch 111/1000\n",
      "0s - loss: 0.2498 - val_loss: 0.2331\n",
      "Epoch 112/1000\n",
      "0s - loss: 0.2496 - val_loss: 0.2319\n",
      "Epoch 113/1000\n",
      "0s - loss: 0.2459 - val_loss: 0.2299\n",
      "Epoch 114/1000\n",
      "0s - loss: 0.2444 - val_loss: 0.2285\n",
      "Epoch 115/1000\n",
      "0s - loss: 0.2425 - val_loss: 0.2268\n",
      "Epoch 116/1000\n",
      "0s - loss: 0.2405 - val_loss: 0.2254\n",
      "Epoch 117/1000\n",
      "0s - loss: 0.2385 - val_loss: 0.2237\n",
      "Epoch 118/1000\n",
      "0s - loss: 0.2374 - val_loss: 0.2218\n",
      "Epoch 119/1000\n",
      "0s - loss: 0.2352 - val_loss: 0.2203\n",
      "Epoch 120/1000\n",
      "0s - loss: 0.2332 - val_loss: 0.2190\n",
      "Epoch 121/1000\n",
      "0s - loss: 0.2326 - val_loss: 0.2181\n",
      "Epoch 122/1000\n",
      "0s - loss: 0.2292 - val_loss: 0.2160\n",
      "Epoch 123/1000\n",
      "0s - loss: 0.2286 - val_loss: 0.2142\n",
      "Epoch 124/1000\n",
      "0s - loss: 0.2275 - val_loss: 0.2128\n",
      "Epoch 125/1000\n",
      "0s - loss: 0.2246 - val_loss: 0.2117\n",
      "Epoch 126/1000\n",
      "0s - loss: 0.2227 - val_loss: 0.2108\n",
      "Epoch 127/1000\n",
      "0s - loss: 0.2210 - val_loss: 0.2097\n",
      "Epoch 128/1000\n",
      "0s - loss: 0.2194 - val_loss: 0.2091\n",
      "Epoch 129/1000\n",
      "0s - loss: 0.2181 - val_loss: 0.2074\n",
      "Epoch 130/1000\n",
      "0s - loss: 0.2163 - val_loss: 0.2052\n",
      "Epoch 131/1000\n",
      "0s - loss: 0.2160 - val_loss: 0.2032\n",
      "Epoch 132/1000\n",
      "0s - loss: 0.2127 - val_loss: 0.2028\n",
      "Epoch 133/1000\n",
      "0s - loss: 0.2112 - val_loss: 0.2029\n",
      "Epoch 134/1000\n",
      "0s - loss: 0.2105 - val_loss: 0.2022\n",
      "Epoch 135/1000\n",
      "0s - loss: 0.2093 - val_loss: 0.1994\n",
      "Epoch 136/1000\n",
      "0s - loss: 0.2075 - val_loss: 0.1977\n",
      "Epoch 137/1000\n",
      "0s - loss: 0.2062 - val_loss: 0.1975\n",
      "Epoch 138/1000\n",
      "0s - loss: 0.2041 - val_loss: 0.1955\n",
      "Epoch 139/1000\n",
      "0s - loss: 0.2023 - val_loss: 0.1936\n",
      "Epoch 140/1000\n",
      "0s - loss: 0.2036 - val_loss: 0.1919\n",
      "Epoch 141/1000\n",
      "0s - loss: 0.2009 - val_loss: 0.1907\n",
      "Epoch 142/1000\n",
      "0s - loss: 0.1983 - val_loss: 0.1902\n",
      "Epoch 143/1000\n",
      "0s - loss: 0.1975 - val_loss: 0.1910\n",
      "Epoch 144/1000\n",
      "0s - loss: 0.1959 - val_loss: 0.1896\n",
      "Epoch 145/1000\n",
      "0s - loss: 0.1940 - val_loss: 0.1869\n",
      "Epoch 146/1000\n",
      "0s - loss: 0.1931 - val_loss: 0.1849\n",
      "Epoch 147/1000\n",
      "0s - loss: 0.1924 - val_loss: 0.1837\n",
      "Epoch 148/1000\n",
      "0s - loss: 0.1907 - val_loss: 0.1830\n",
      "Epoch 149/1000\n",
      "0s - loss: 0.1886 - val_loss: 0.1831\n",
      "Epoch 150/1000\n",
      "0s - loss: 0.1873 - val_loss: 0.1830\n",
      "Epoch 151/1000\n",
      "0s - loss: 0.1864 - val_loss: 0.1824\n",
      "Epoch 152/1000\n",
      "0s - loss: 0.1857 - val_loss: 0.1815\n",
      "Epoch 153/1000\n",
      "0s - loss: 0.1845 - val_loss: 0.1779\n",
      "Epoch 154/1000\n",
      "0s - loss: 0.1824 - val_loss: 0.1763\n",
      "Epoch 155/1000\n",
      "0s - loss: 0.1817 - val_loss: 0.1753\n",
      "Epoch 156/1000\n",
      "0s - loss: 0.1809 - val_loss: 0.1751\n",
      "Epoch 157/1000\n",
      "0s - loss: 0.1789 - val_loss: 0.1738\n",
      "Epoch 158/1000\n",
      "0s - loss: 0.1774 - val_loss: 0.1733\n",
      "Epoch 159/1000\n",
      "0s - loss: 0.1764 - val_loss: 0.1733\n",
      "Epoch 160/1000\n",
      "0s - loss: 0.1758 - val_loss: 0.1726\n",
      "Epoch 161/1000\n",
      "0s - loss: 0.1745 - val_loss: 0.1713\n",
      "Epoch 162/1000\n",
      "0s - loss: 0.1726 - val_loss: 0.1686\n",
      "Epoch 163/1000\n",
      "0s - loss: 0.1721 - val_loss: 0.1674\n",
      "Epoch 164/1000\n",
      "0s - loss: 0.1716 - val_loss: 0.1666\n",
      "Epoch 165/1000\n",
      "0s - loss: 0.1697 - val_loss: 0.1676\n",
      "Epoch 166/1000\n",
      "0s - loss: 0.1692 - val_loss: 0.1685\n",
      "Epoch 167/1000\n",
      "0s - loss: 0.1686 - val_loss: 0.1674\n",
      "Epoch 168/1000\n",
      "0s - loss: 0.1672 - val_loss: 0.1661\n",
      "Epoch 169/1000\n",
      "0s - loss: 0.1658 - val_loss: 0.1650\n",
      "Epoch 170/1000\n",
      "0s - loss: 0.1645 - val_loss: 0.1627\n",
      "Epoch 171/1000\n",
      "0s - loss: 0.1633 - val_loss: 0.1605\n",
      "Epoch 172/1000\n",
      "0s - loss: 0.1647 - val_loss: 0.1593\n",
      "Epoch 173/1000\n",
      "0s - loss: 0.1620 - val_loss: 0.1593\n",
      "Epoch 174/1000\n",
      "0s - loss: 0.1595 - val_loss: 0.1610\n",
      "Epoch 175/1000\n",
      "0s - loss: 0.1603 - val_loss: 0.1640\n",
      "Epoch 176/1000\n",
      "0s - loss: 0.1610 - val_loss: 0.1634\n",
      "Epoch 177/1000\n",
      "0s - loss: 0.1597 - val_loss: 0.1608\n",
      "Epoch 178/1000\n",
      "0s - loss: 0.1576 - val_loss: 0.1565\n",
      "Epoch 179/1000\n",
      "0s - loss: 0.1555 - val_loss: 0.1542\n",
      "Epoch 180/1000\n",
      "0s - loss: 0.1553 - val_loss: 0.1533\n",
      "Epoch 181/1000\n",
      "0s - loss: 0.1546 - val_loss: 0.1523\n",
      "Epoch 182/1000\n",
      "0s - loss: 0.1537 - val_loss: 0.1520\n",
      "Epoch 183/1000\n",
      "0s - loss: 0.1524 - val_loss: 0.1525\n",
      "Epoch 184/1000\n",
      "0s - loss: 0.1513 - val_loss: 0.1529\n",
      "Epoch 185/1000\n",
      "0s - loss: 0.1509 - val_loss: 0.1524\n",
      "Epoch 186/1000\n",
      "0s - loss: 0.1498 - val_loss: 0.1526\n",
      "Epoch 187/1000\n",
      "0s - loss: 0.1504 - val_loss: 0.1543\n",
      "Epoch 00186: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8ca9bc470>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "path = \"./UW_deep_learning/data/\"\n",
    "\n",
    "iris_file=\"iris.csv\"\n",
    "file_iris = os.path.join(path,iris_file)\n",
    "df=pd.read_csv(file_iris,na_values=['NA','?'])\n",
    "\n",
    "species = encode_text_index(df,\"species\")\n",
    "x,y = to_xy(df,\"species\")\n",
    "\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(5, activation='relu')) # Hidden 2\n",
    "model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor], verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 2 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "predict = np.argmax(pred,axis=1)\n",
    "print (predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_compare = np.argmax(y_test, axis=1)\n",
    "score = metrics.accuracy_score(y_compare, predict)\n",
    "print (\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Accuracy score with Log-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array of prediction\n",
      "[ 0.0785 92.293   7.6285]\n",
      "As percentage probability\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0008, 0.9229, 0.0763],\n",
       "       [0.9999, 0.0001, 0.    ],\n",
       "       [0.0008, 0.0068, 0.9924],\n",
       "       [0.0016, 0.8103, 0.188 ],\n",
       "       [0.0009, 0.8456, 0.1534]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score: 0.08401772963083874\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#generate predictions\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(\"Numpy array of prediction\")\n",
    "print (pred[0]*100)\n",
    "\n",
    "print(\"As percentage probability\")\n",
    "\n",
    "display(pred[:5])\n",
    "\n",
    "score = metrics.log_loss(y_test,pred)\n",
    "print (\"Log loss score: {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from numpy import arange, sin, pi\n",
    "\n",
    "t = arange(1e-5, 5.0, 0.0001)\n",
    "\n",
    "fig = figure(1,figsize=(12,10))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(t, np.log(t))\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim((-8, 1.5))\n",
    "ax1.set_xlim((-.1,2))\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_title('log(x)')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/NNDL/lib/python3.6/site-packages/ipykernel_launcher.py:74: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 298 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "0s - loss: 1766954.7336 - val_loss: 703652.8125\n",
      "Epoch 2/1000\n",
      "0s - loss: 330941.5853 - val_loss: 41179.2986\n",
      "Epoch 3/1000\n",
      "0s - loss: 10421.2190 - val_loss: 20659.9627\n",
      "Epoch 4/1000\n",
      "0s - loss: 31302.0810 - val_loss: 31620.2797\n",
      "Epoch 5/1000\n",
      "0s - loss: 18020.6448 - val_loss: 4018.6630\n",
      "Epoch 6/1000\n",
      "0s - loss: 1150.0858 - val_loss: 830.1512\n",
      "Epoch 7/1000\n",
      "0s - loss: 1617.2619 - val_loss: 1532.9811\n",
      "Epoch 8/1000\n",
      "0s - loss: 995.1227 - val_loss: 226.8161\n",
      "Epoch 9/1000\n",
      "0s - loss: 196.9447 - val_loss: 267.9817\n",
      "Epoch 10/1000\n",
      "0s - loss: 265.8554 - val_loss: 241.1837\n",
      "Epoch 11/1000\n",
      "0s - loss: 199.4740 - val_loss: 158.5872\n",
      "Epoch 12/1000\n",
      "0s - loss: 180.7326 - val_loss: 158.8536\n",
      "Epoch 13/1000\n",
      "0s - loss: 179.8226 - val_loss: 158.8252\n",
      "Epoch 14/1000\n",
      "0s - loss: 174.6246 - val_loss: 162.9010\n",
      "Epoch 15/1000\n",
      "0s - loss: 175.4619 - val_loss: 160.5696\n",
      "Epoch 16/1000\n",
      "0s - loss: 175.2731 - val_loss: 161.0389\n",
      "Epoch 17/1000\n",
      "0s - loss: 174.5193 - val_loss: 157.6252\n",
      "Epoch 18/1000\n",
      "0s - loss: 175.5612 - val_loss: 158.7642\n",
      "Epoch 19/1000\n",
      "0s - loss: 174.7660 - val_loss: 159.3536\n",
      "Epoch 20/1000\n",
      "0s - loss: 174.6629 - val_loss: 159.8500\n",
      "Epoch 21/1000\n",
      "0s - loss: 174.8226 - val_loss: 160.6590\n",
      "Epoch 22/1000\n",
      "0s - loss: 174.6232 - val_loss: 160.5720\n",
      "Epoch 23/1000\n",
      "0s - loss: 174.2260 - val_loss: 158.3581\n",
      "Epoch 00022: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8cb48e5f8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "cars = df['name']\n",
    "df.drop('name',1,inplace=True)\n",
    "missing_median(df, 'horsepower')\n",
    "x,y = to_xy(df,\"mpg\")\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 158.3580780029297\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Measure MSE error.  \n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 12.584040641784668\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/NNDL/lib/python3.6/site-packages/ipykernel_launcher.py:74: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold #1\n",
      "Epoch 00014: early stopping\n",
      "Fold score (RMSE) 9.949836730957031\n",
      "fold #2\n",
      "Epoch 00287: early stopping\n",
      "Fold score (RMSE) 3.847343683242798\n",
      "fold #3\n",
      "Epoch 00047: early stopping\n",
      "Fold score (RMSE) 8.513518333435059\n",
      "fold #4\n",
      "Epoch 00013: early stopping\n",
      "Fold score (RMSE) 13.908507347106934\n",
      "fold #5\n",
      "Epoch 00281: early stopping\n",
      "Fold score (RMSE) 3.613138437271118\n",
      "Final score (RMSE:) 8.856208801269531 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "cars = df['name']\n",
    "df.drop('name',1,inplace=True)\n",
    "missing_median(df, 'horsepower')\n",
    "x,y = to_xy(df,\"mpg\")\n",
    "\n",
    "\n",
    "# K-FOLD Validation\n",
    "\n",
    "kf = KFold(5)\n",
    "\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    fold += 1\n",
    "    print (\"fold #{}\".format(fold))\n",
    "    \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "#     model.add(Dense(1))\n",
    "#     model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode = 'auto')\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=0, epochs=1000)\n",
    "    pred = model.predict(x_test)\n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)\n",
    "    \n",
    "    score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
    "    print (\"Fold score (RMSE) {}\".format(score))\n",
    "    \n",
    "\n",
    "#Build the oos prediction list and calculate the error\n",
    "\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y, oos_pred))\n",
    "print (\"Final score (RMSE:) {} \".format(score))\n",
    "\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat([df, oos_y, oos_pred], axis= 1)\n",
    "filename_write = 'crossvalidation.csv'\n",
    "oosDF.to_csv(filename_write,index=False)\n",
    "\n",
    "# Split into train/test\n",
    "# x_train, x_test, y_train, y_test = train_test_split(    \n",
    "#     x, y, test_size=0.25, random_state=45)\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "# model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/NNDL/lib/python3.6/site-packages/ipykernel_launcher.py:71: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Epoch 00307: early stopping\n",
      "FOld score (accuracy): \n",
      "Fold 2:\n",
      "Epoch 00244: early stopping\n",
      "FOld score (accuracy): \n",
      "Fold 3:\n",
      "Epoch 00275: early stopping\n",
      "FOld score (accuracy): \n",
      "Fold 4:\n",
      "Epoch 00287: early stopping\n",
      "FOld score (accuracy): \n",
      "Fold 5:\n",
      "Epoch 00333: early stopping\n",
      "FOld score (accuracy): \n",
      "Final score (RMSE:) 0.16329931618554522 \n"
     ]
    }
   ],
   "source": [
    "path = \"./UW_deep_learning/data/\"\n",
    "\n",
    "iris_file=\"iris.csv\"\n",
    "file_iris = os.path.join(path,iris_file)\n",
    "df=pd.read_csv(file_iris,na_values=['NA','?'])\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop= True)\n",
    "\n",
    "species = encode_text_index(df,\"species\")\n",
    "x,y = to_xy(df,\"species\")\n",
    "\n",
    "kf = KFold(5)\n",
    "\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print (\"Fold {}:\".format(fold))\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dense(5, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test), callbacks=[monitor], verbose=0,epochs=1000)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1)\n",
    "    oos_pred.append(pred)\n",
    "    \n",
    "    y_compare = np.argmax(y_test,axis=1)\n",
    "#     print (\"shape of test data input, output : {} {} {} {}\". format(pred.shape, y_test.shape, np.argmax(y_test,axis=1).shape))\n",
    "\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(\"FOld score (accuracy): \".format(score))\n",
    "    \n",
    "\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y_compare, oos_pred))\n",
    "print (\"Final score (RMSE:) {} \".format(score))\n",
    "\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat([df, oos_y, oos_pred], axis= 1)\n",
    "filename_write = 'crossvalidation_classification.csv'\n",
    "oosDF.to_csv(filename_write,index=False)\n",
    "    \n",
    "\n",
    "\n",
    "# Split into train/test\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
